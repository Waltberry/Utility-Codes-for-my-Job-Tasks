{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad810ca8",
   "metadata": {},
   "source": [
    "`Task`: Editing to make on the Nokia and Huawei SLA Report\n",
    "- Bandwidth from 1GBits\n",
    "- Filter out Enterprise Links â€“ these are links that has   LL_LM , LL_CO , INT_LM , INT_CO \n",
    "- Filter out Zero Reachability \n",
    "- Filter out all the IPDCN Links\n",
    "- Filter out all the Ericsson \n",
    "- Comparing dublicates\n",
    "- Add more conditions for 70-80, 80-90, and 90 and above exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c535c3",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7deabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data without excel formulas\n",
    "file_path = 'CTN Nokia Created.xlsx' # Nokia\n",
    "# file_path = 'CTN Huawei Created.xlsx' # Huawei\n",
    "# file_path = 'Book1.xlsx' # Huawei\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5328dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6314355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_multiply(value):\n",
    "    if not isinstance(value, str):\n",
    "        return 0\n",
    "    if value.endswith('G'):\n",
    "        num_value=float(value[:-2]) * 1000\n",
    "    elif value.endswith('M'):\n",
    "        num_value=float(value[:-2]) * 1\n",
    "    elif value.endswith('T'):\n",
    "        num_value=float(value[:-2]) * 1000000\n",
    "    else:\n",
    "        return value\n",
    "    return int(num_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f0552f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_path, sheet_name=0, header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0c80f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def columns_to_2dp(df=df):\n",
    "    \n",
    "    # Assuming your DataFrame is named 'df' and you want to convert specific columns\n",
    "    columns_to_convert = ['Reachability', 'Utilization', 'Utilization.1',\n",
    "                          'Utilization.2', 'Utilization.3', 'Utilization.4', 'Utilization.5', 'Utilization.6']\n",
    "\n",
    "    # Fill NA or blanks with zero\n",
    "    df[columns_to_convert] = df[columns_to_convert].fillna(0)\n",
    "\n",
    "    # Define a custom rounding function\n",
    "    def round_up(x):\n",
    "        if x % 1 >= 0.005:\n",
    "            return np.ceil(x * 100) / 100 \n",
    "        else:\n",
    "            return np.floor(x)\n",
    "\n",
    "    # Round up float values to the nearest whole number based on the custom rounding function\n",
    "    df[columns_to_convert] = df[columns_to_convert].applymap(round_up)\n",
    "\n",
    "#     # Convert rounded float columns to integers\n",
    "#     df[columns_to_convert] = df[columns_to_convert].astype(np.int64)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7072eb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_task(df=df):\n",
    "    # load excel data\n",
    "    \n",
    "    '''Convert to int ['Reachability', 'Utilization', 'Utilization.1',\n",
    "    'Utilization.2', 'Utilization.3', 'Utilization.4', 'Utilization.5', 'Utilization.6']''' \n",
    "    columns_to_2dp()\n",
    "    #Display shape\n",
    "    print('Initial Total per region:',region_counts := df['Region'].value_counts())\n",
    "    print(\"initial shape:\", df.shape)\n",
    "    print(\"converted dtypes:\", df.dtypes)\n",
    "    \n",
    "    # Filter Bandwidth >= 1GBits\n",
    "    df_bandwidth_blank=df[df['Bandwidth'].isnull()]\n",
    "    df_bandwidth_blank.head()\n",
    "    df = df.dropna(subset=['Bandwidth'])\n",
    "    pattern = r'(\\d+(?:\\.\\d+)? [GMT])'\n",
    "    df['Bandwidth_extracted'] = df['Bandwidth'].str.extract(pattern)    \n",
    "    df['Bandwidth_extracted'] = df['Bandwidth_extracted'].apply(convert_and_multiply).astype(int)\n",
    "    df = df[df['Bandwidth_extracted']>= 1000]\n",
    "    \n",
    "    print(\"1st step:- After Bandwidth filter:\", df.shape)\n",
    "    print(\"Shape of blank bandwidth data:\", df_bandwidth_blank.shape)\n",
    "    df_bandwidth_blank = df_bandwidth_blank[df_bandwidth_blank.iloc[:, -1] >= 4]\n",
    "    print('How many blank bandwidth that meets the utilization rule:',\n",
    "          df_bandwidth_blanc :=df_bandwidth_blank['Region'].value_counts())\n",
    "    \n",
    "    # Filter out Enterprise Links (LL_LM, LL_CO, INT_LM, INT_CO)\n",
    "    names_to_remove = ['LL_LM', 'LL_CO', 'INT_LM', 'INT_CO', 'to-Ericsson-6672']\n",
    "    df = df[~df['Interface'].str.endswith(tuple(names_to_remove))]\n",
    "\n",
    "    print(\"2nd step:- After Enterprise filter:\", df.shape)\n",
    "    \n",
    "    # Filter out zero reachability\n",
    "    df_reachability_blank = df[df['Reachability'].isnull()] #Saving reachability with blank data\n",
    "    df = df[df['Reachability'] > 0] # removes zeros and below\n",
    "    \n",
    "    print(\"3rd step:- After zero reachability filter:\", df.shape)\n",
    "    \n",
    "    # Filter out all the IPDCN Links\n",
    "    df = df[~df['Interface'].str.endswith('IPDCN')]\n",
    "    df = df[~df['Interface'].str.contains('IPDCN')]\n",
    "    \n",
    "    print(\"4th step:- After IPDCN Links removed:\", df.shape)\n",
    "    \n",
    "    #Filter out all the Ericsson Links\n",
    "    df = df[~df['Interface'].str.contains('to_Ericsson|to-Ericsson', case=False)]\n",
    "    \n",
    "    # Comparing dublicates\n",
    "    df['Interface_new'] = df['Interface'].str.extract(r'^([^_]+)')\n",
    "    df['Total_util'] = df.filter(like='Utilization').sum(axis=1)\n",
    "    # Sort the DataFrame by 'total_util' column in descending order\n",
    "    df.sort_values('Total_util', ascending=False, inplace=True)\n",
    "    # Drop duplicates based on 'interface_new' column, keeping the first occurrence (highest total_util)\n",
    "    df.drop_duplicates(subset='Interface_new', keep='first', inplace=True)\n",
    "\n",
    "    \n",
    "    print(\"Final step:- After all conditions are met:\", df.shape)\n",
    "    \n",
    "    # Count by Region\n",
    "    display('After conditions are met:- Total per region:',region_counts := df['Region'].value_counts())\n",
    "    \n",
    "    # Count the number of NaN values in the column\n",
    "    nan_count = df['Region'].isna().sum()\n",
    "\n",
    "    # Count the number of blank values in the column\n",
    "    blank_count = (df['Region'] == '').sum()\n",
    "    \n",
    "    print('How many nan,blank are in Region Column:', nan_count, blank_count)\n",
    "    \n",
    "    df.drop(['Bandwidth_extracted', 'Interface_new', 'Total_util'], axis=1, inplace=True)\n",
    "        \n",
    "    # Filter out data in column 11 with value 4 and above\n",
    "    df_filtered90andabove = df[df['90% and above'] >= 4]\n",
    "    df_filtered80_90 = df[df['80% to 90%'] >= 4]\n",
    "    df_filtered70_80 = df[df['70% to 80%'] >= 4]\n",
    "    \n",
    "    # blank\n",
    "#     print(\"Shape of blank reachability data:\", df_reachability_blank.shape)\n",
    "#     df_filtered_blank = df_reachability_blank[df_reachability_blank.iloc[:, -2] >= 4]\n",
    "#     print('How many blanks per region that meets rule:', df_filtered_blanc :=df_filtered_blank['Region'].value_counts())\n",
    "#     print(\"shape of filtered data:\", df_filtered.shape)\n",
    "    \n",
    "#     # Count the number of NaN values in the column\n",
    "#     nan_count_f = df_filtered['Region'].isna().sum()\n",
    "#     # Count the number of blank values in the column\n",
    "#     blank_count_f = (df_filtered['Region'] == '').sum()\n",
    "    \n",
    "#     print('How many nan,blank are in Region Column in Filtered:', nan_count_f, blank_count_f)\n",
    "    \n",
    "    # Group by region\n",
    "    print('How many are above 4 in the 90 and above condition:',\n",
    "          region_counts := df_filtered90andabove['Region'].value_counts(), df_filtered90andabove.shape)\n",
    "    print('-----')\n",
    "    print('How many are above 4 in the 80 to 90 condition:',\n",
    "          region_counts := df_filtered80_90['Region'].value_counts(), df_filtered80_90.shape)\n",
    "    print('-----')\n",
    "    print('How many are above 4 in the 70 to 80 condition:',\n",
    "          region_counts := df_filtered70_80['Region'].value_counts(), df_filtered70_80.shape)\n",
    "    print('-----')\n",
    "    \n",
    "    \n",
    "\n",
    "    # Merging the filted data.\n",
    "\n",
    "    # Concatenate the dataframes\n",
    "    df_filtered = pd.concat([df_filtered90andabove, df_filtered80_90, df_filtered70_80])\n",
    "\n",
    "    # Remove duplicates based on all columns\n",
    "    df_filtered = df_filtered.drop_duplicates()\n",
    "\n",
    "    # Sort by the '90% and above' column in descending order\n",
    "    df_filtered = df_filtered.sort_values(by=['90% and above', '80% to 90%', '70% to 80%'],\n",
    "                                          ascending=[False, False, False])\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     df.drop(['Bandwidth_extracted', 'Interface_new', 'Total_util'], axis=1, inplace=True)\n",
    "#     df_filtered.drop(['Bandwidth_extracted', 'Interface_new', 'Total_util'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df_filtered.reset_index(drop=True, inplace=True)\n",
    "    df.index += 1\n",
    "    df_filtered.index += 1\n",
    "    df.index.name = '#'\n",
    "    df_filtered.index.name = '#'\n",
    "        \n",
    "    save_df=df.to_excel('done_'+file_path, sheet_name=file_path)\n",
    "    save_filtered=df_filtered.to_excel('filtered_' + file_path, sheet_name=file_path)\n",
    "    return save_df, save_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a5ffc78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Total per region: Asaba                             8931\n",
      "Kano                              5916\n",
      "Enugu                             2229\n",
      "PHC                                  9\n",
      "T2632_CHINEDU EZENYILLI_SASR_1       8\n",
      "Abuja                                7\n",
      "unknown                              1\n",
      "ENUGU                                1\n",
      "Name: Region, dtype: int64\n",
      "initial shape: (52085, 14)\n",
      "converted dtypes: Region            object\n",
      "Interface         object\n",
      "Bandwidth         object\n",
      "Reachability     float64\n",
      "Utilization      float64\n",
      "Utilization.1    float64\n",
      "Utilization.2    float64\n",
      "Utilization.3    float64\n",
      "Utilization.4    float64\n",
      "Utilization.5    float64\n",
      "Utilization.6    float64\n",
      "90% and above      int64\n",
      "80% to 90%         int64\n",
      "70% to 80%         int64\n",
      "dtype: object\n",
      "1st step:- After Bandwidth filter: (16104, 15)\n",
      "Shape of blank bandwidth data: (35788, 14)\n",
      "How many blank bandwidth that meets the utilization rule: Series([], Name: Region, dtype: int64)\n",
      "2nd step:- After Enterprise filter: (14606, 15)\n",
      "3rd step:- After zero reachability filter: (13705, 15)\n",
      "4th step:- After IPDCN Links removed: (13703, 15)\n",
      "Final step:- After all conditions are met: (1088, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_43268\\59886722.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Bandwidth_extracted'] = df['Bandwidth'].str.extract(pattern)\n",
      "C:\\Users\\admin\\AppData\\Local\\Temp\\ipykernel_43268\\59886722.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Bandwidth_extracted'] = df['Bandwidth_extracted'].apply(convert_and_multiply).astype(int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'After conditions are met:- Total per region:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Asaba    548\n",
       "Kano     394\n",
       "Enugu    146\n",
       "Name: Region, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many nan,blank are in Region Column: 0 0\n",
      "How many are above 4 in the 90 and above condition: Asaba    6\n",
      "Kano     1\n",
      "Name: Region, dtype: int64 (7, 14)\n",
      "-----\n",
      "How many are above 4 in the 80 to 90 condition: Kano    1\n",
      "Name: Region, dtype: int64 (1, 14)\n",
      "-----\n",
      "How many are above 4 in the 70 to 80 condition: Kano     4\n",
      "Enugu    2\n",
      "Asaba    2\n",
      "Name: Region, dtype: int64 (8, 14)\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b506ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Checking if any of this words are found.\n",
    "\n",
    "# # Define the patterns and keywords\n",
    "# patterns = ['LL_LM$', 'LL_CO$', 'INT_LM$', 'INT_CO$', 'IPDCN$']\n",
    "# keyword = 'Ericsson'\n",
    "\n",
    "# # Create a boolean mask to filter the rows\n",
    "# mask = df['Column'].str.contains('|'.join(patterns), case=False, regex=True) & \\\n",
    "#        df['Column'].str.contains(keyword, case=False, regex=False)\n",
    "\n",
    "# # Apply the mask to the DataFrame\n",
    "# filtered_df = df[mask]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
